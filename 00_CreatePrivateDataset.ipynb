{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Kaggle Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This will add the pydicom decompressors\n",
    "!pip install pydicom pylibjpeg pylibjpeg-libjpeg\n",
    "# Re-install a compatible version of numpy\n",
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!STOP AND RESTART SESSION!!\n",
    "## YOU ONLY NEED TO DO THIS ONCE\n",
    "## This makes sure the above dependencies are installed, and we're able to decompress images.\n",
    "## You can skip the first two cells after restarting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:26:16.664786Z",
     "iopub.status.busy": "2025-11-27T00:26:16.664443Z",
     "iopub.status.idle": "2025-11-27T00:26:17.065142Z",
     "shell.execute_reply": "2025-11-27T00:26:17.063647Z",
     "shell.execute_reply.started": "2025-11-27T00:26:16.664764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import h5py\n",
    "import cv2\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "random_state = 24\n",
    "\n",
    "# Suppress the DeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:09.139765Z",
     "iopub.status.busy": "2025-11-27T00:12:09.138919Z",
     "iopub.status.idle": "2025-11-27T00:12:09.144960Z",
     "shell.execute_reply": "2025-11-27T00:12:09.143824Z",
     "shell.execute_reply.started": "2025-11-27T00:12:09.139725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set paths to the Kaggle data\n",
    "bbox_csv_path = '/kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_bounding_boxes.csv'\n",
    "\n",
    "# We're using the clean version from the metadata dataset\n",
    "meta_csv_path = '/kaggle/input/rsna-2022-spine-fracture-detection-metadata/meta_train_clean.csv'\n",
    "\n",
    "# This is the path to all 136GB of images\n",
    "image_data_path = '/kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/'\n",
    "\n",
    "# Set the output path\n",
    "hdf5_save_path = '/kaggle/working/fracture_dataset_subset.h5'\n",
    "\n",
    "# Settings\n",
    "image_size = 256\n",
    "negative_ratio = 3 # for each positive, we add 3 negative samples\n",
    "max_boxes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:10.814233Z",
     "iopub.status.busy": "2025-11-27T00:12:10.813488Z",
     "iopub.status.idle": "2025-11-27T00:12:11.415081Z",
     "shell.execute_reply": "2025-11-27T00:12:11.413213Z",
     "shell.execute_reply.started": "2025-11-27T00:12:10.814197Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Slice</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>SliceThickness</th>\n",
       "      <th>ImagePositionPatient_x</th>\n",
       "      <th>ImagePositionPatient_y</th>\n",
       "      <th>ImagePositionPatient_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-52.308</td>\n",
       "      <td>-27.712</td>\n",
       "      <td>7.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-52.308</td>\n",
       "      <td>-27.712</td>\n",
       "      <td>6.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-52.308</td>\n",
       "      <td>-27.712</td>\n",
       "      <td>6.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  Slice  ImageHeight  ImageWidth  SliceThickness  \\\n",
       "0  1.2.826.0.1.3680043.10001      1          512         512           0.625   \n",
       "1  1.2.826.0.1.3680043.10001      2          512         512           0.625   \n",
       "2  1.2.826.0.1.3680043.10001      3          512         512           0.625   \n",
       "\n",
       "   ImagePositionPatient_x  ImagePositionPatient_y  ImagePositionPatient_z  \n",
       "0                 -52.308                 -27.712                   7.282  \n",
       "1                 -52.308                 -27.712                   6.657  \n",
       "2                 -52.308                 -27.712                   6.032  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and view metadata\n",
    "meta_df = pd.read_csv(meta_csv_path)\n",
    "meta_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:12.718887Z",
     "iopub.status.busy": "2025-11-27T00:12:12.718561Z",
     "iopub.status.idle": "2025-11-27T00:12:12.740344Z",
     "shell.execute_reply": "2025-11-27T00:12:12.739396Z",
     "shell.execute_reply.started": "2025-11-27T00:12:12.718866Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>slice_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10051</td>\n",
       "      <td>219.27715</td>\n",
       "      <td>216.71419</td>\n",
       "      <td>17.30440</td>\n",
       "      <td>20.38517</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10051</td>\n",
       "      <td>221.56460</td>\n",
       "      <td>216.71419</td>\n",
       "      <td>17.87844</td>\n",
       "      <td>25.24362</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10051</td>\n",
       "      <td>216.82151</td>\n",
       "      <td>221.62546</td>\n",
       "      <td>27.00959</td>\n",
       "      <td>26.37454</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID          x          y     width    height  \\\n",
       "0  1.2.826.0.1.3680043.10051  219.27715  216.71419  17.30440  20.38517   \n",
       "1  1.2.826.0.1.3680043.10051  221.56460  216.71419  17.87844  25.24362   \n",
       "2  1.2.826.0.1.3680043.10051  216.82151  221.62546  27.00959  26.37454   \n",
       "\n",
       "   slice_number  \n",
       "0           133  \n",
       "1           134  \n",
       "2           135  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and view bounding box data\n",
    "bbox_df = pd.read_csv(bbox_csv_path)\n",
    "bbox_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:15.223665Z",
     "iopub.status.busy": "2025-11-27T00:12:15.223323Z",
     "iopub.status.idle": "2025-11-27T00:12:16.060643Z",
     "shell.execute_reply": "2025-11-27T00:12:16.059663Z",
     "shell.execute_reply.started": "2025-11-27T00:12:15.223642Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating bounding boxes per slice...\n",
      "Found 7217 slices with bounding boxes.\n",
      "Metadata merge complete.\n"
     ]
    }
   ],
   "source": [
    "# Load and merge metadata\n",
    "\n",
    "# Rename slice columns to match\n",
    "meta_df = meta_df.rename(columns={'Slice': 'SliceNumber'})\n",
    "bbox_df = bbox_df.rename(columns={'slice_number': 'SliceNumber'})\n",
    "\n",
    "# Group by slice and aggregate bboxes into a list [x, y, width, height]\n",
    "print('Aggregating bounding boxes per slice...')\n",
    "bbox_grouped = bbox_df.groupby(['StudyInstanceUID', 'SliceNumber'])[['x', 'y', 'width', 'height']].apply(\n",
    "    lambda x: x.values.tolist()\n",
    ").reset_index(name='bboxes')\n",
    "print(f\"Found {len(bbox_grouped)} slices with bounding boxes.\")\n",
    "\n",
    "# Merge all slices with the bounding box data\n",
    "all_slices_df = pd.merge(\n",
    "    meta_df,\n",
    "    bbox_grouped,\n",
    "    on=['StudyInstanceUID', 'SliceNumber'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create final labels\n",
    "# 'is_positive' is 1 if 'bboxes' is not NaN, 0 otherwise\n",
    "all_slices_df['is_positive'] = all_slices_df['bboxes'].notna().astype(int)\n",
    "\n",
    "# Fill NaN in 'bboxes' with an empty list for consistency\n",
    "all_slices_df['bboxes'] = all_slices_df['bboxes'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "print('Metadata merge complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:18.494995Z",
     "iopub.status.busy": "2025-11-27T00:12:18.494043Z",
     "iopub.status.idle": "2025-11-27T00:12:18.513082Z",
     "shell.execute_reply": "2025-11-27T00:12:18.511988Z",
     "shell.execute_reply.started": "2025-11-27T00:12:18.494954Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageHeight\n",
      "512    710819\n",
      "768       782\n",
      "Name: count, dtype: int64\n",
      "\n",
      " ImageWidth\n",
      "512    710574\n",
      "768       782\n",
      "519       245\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check image sizes\n",
    "print(all_slices_df['ImageHeight'].value_counts())\n",
    "print('\\n',all_slices_df['ImageWidth'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:21.135324Z",
     "iopub.status.busy": "2025-11-27T00:12:21.134222Z",
     "iopub.status.idle": "2025-11-27T00:12:21.203685Z",
     "shell.execute_reply": "2025-11-27T00:12:21.202500Z",
     "shell.execute_reply.started": "2025-11-27T00:12:21.135260Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageHeight\n",
      "512    710574\n",
      "Name: count, dtype: int64\n",
      "\n",
      " ImageWidth\n",
      "512    710574\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter for 512x512 images only\n",
    "all_slices_df = all_slices_df[\n",
    "    (all_slices_df['ImageHeight'] == 512) & \n",
    "    (all_slices_df['ImageWidth'] == 512)\n",
    "]\n",
    "print(all_slices_df['ImageHeight'].value_counts())\n",
    "print('\\n',all_slices_df['ImageWidth'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:24.614098Z",
     "iopub.status.busy": "2025-11-27T00:12:24.613705Z",
     "iopub.status.idle": "2025-11-27T00:12:24.692509Z",
     "shell.execute_reply": "2025-11-27T00:12:24.691384Z",
     "shell.execute_reply.started": "2025-11-27T00:12:24.614016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patients: 2016\n",
      "Positive Patients: 234\n"
     ]
    }
   ],
   "source": [
    "# Create patient-level splits\n",
    "\n",
    "# Define Split Ratios\n",
    "# 70% Train, 15% Validation, 15% Test\n",
    "train_size = 0.70\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "# Prepare Patient-Level Data\n",
    "# One row per patient for splitting\n",
    "patient_df = all_slices_df.groupby('StudyInstanceUID').agg({\n",
    "    'is_positive': 'max', # If patient has any fracture slice, they are positive\n",
    "    'SliceNumber': 'count' # Count slices per patient\n",
    "}).reset_index()\n",
    "\n",
    "print(f'Total Patients: {len(patient_df)}')\n",
    "print(f\"Positive Patients: {patient_df['is_positive'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:27.074142Z",
     "iopub.status.busy": "2025-11-27T00:12:27.073807Z",
     "iopub.status.idle": "2025-11-27T00:12:27.088991Z",
     "shell.execute_reply": "2025-11-27T00:12:27.087924Z",
     "shell.execute_reply.started": "2025-11-27T00:12:27.074119Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Patient Count: 1411\n",
      "Validation Patient Count: 302\n",
      "Test Patient Count: 303\n"
     ]
    }
   ],
   "source": [
    "# First split: train / (val + test)\n",
    "\n",
    "# We use GroupShuffleSplit to split by patient id while keeping class balance\n",
    "splitter = GroupShuffleSplit(test_size=(val_size + test_size), n_splits=1, random_state=42)\n",
    "train_idxs, temp_idxs = next(splitter.split(patient_df, y=patient_df['is_positive'], groups=patient_df['StudyInstanceUID']))\n",
    "train_patients = patient_df.iloc[train_idxs]\n",
    "temp_patients = patient_df.iloc[temp_idxs]\n",
    "\n",
    "# Second Split: val and test\n",
    "# Split the remaining 30% into two equal halves (15% Val, 15% Test)\n",
    "splitter_2 = GroupShuffleSplit(test_size=0.5, n_splits=1, random_state=42)\n",
    "val_idxs, test_idxs = next(splitter_2.split(temp_patients, y=temp_patients['is_positive'], groups=temp_patients['StudyInstanceUID']))\n",
    "\n",
    "val_patients = temp_patients.iloc[val_idxs]\n",
    "test_patients = temp_patients.iloc[test_idxs]\n",
    "\n",
    "print(f'Train Patient Count: {len(train_patients)}')\n",
    "print(f'Validation Patient Count: {len(val_patients)}')\n",
    "print(f'Test Patient Count: {len(test_patients)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:28.854045Z",
     "iopub.status.busy": "2025-11-27T00:12:28.853245Z",
     "iopub.status.idle": "2025-11-27T00:12:29.105151Z",
     "shell.execute_reply": "2025-11-27T00:12:29.103880Z",
     "shell.execute_reply.started": "2025-11-27T00:12:28.854014Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split column created.\n"
     ]
    }
   ],
   "source": [
    "# Map splits back to slice dataframe based on patient id\n",
    "# 0 = Train, 1 = Val, 2 = Test\n",
    "train_uids = set(train_patients['StudyInstanceUID'])\n",
    "val_uids = set(val_patients['StudyInstanceUID'])\n",
    "test_uids = set(test_patients['StudyInstanceUID'])\n",
    "\n",
    "def assign_split(uid):\n",
    "    if uid in train_uids: return 0\n",
    "    if uid in val_uids: return 1\n",
    "    if uid in test_uids: return 2\n",
    "\n",
    "all_slices_df['split'] = all_slices_df['StudyInstanceUID'].apply(assign_split)\n",
    "print('Split column created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:31.459245Z",
     "iopub.status.busy": "2025-11-27T00:12:31.458478Z",
     "iopub.status.idle": "2025-11-27T00:12:31.779966Z",
     "shell.execute_reply": "2025-11-27T00:12:31.778983Z",
     "shell.execute_reply.started": "2025-11-27T00:12:31.459215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SliceNumber</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>SliceThickness</th>\n",
       "      <th>ImagePositionPatient_x</th>\n",
       "      <th>ImagePositionPatient_y</th>\n",
       "      <th>ImagePositionPatient_z</th>\n",
       "      <th>bboxes</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.25600</td>\n",
       "      <td>155</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-38.300000</td>\n",
       "      <td>-74.750</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.24045</td>\n",
       "      <td>281</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-115.009300</td>\n",
       "      <td>-52.509310</td>\n",
       "      <td>1936.500</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.14348</td>\n",
       "      <td>352</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-46.832031</td>\n",
       "      <td>-255.832031</td>\n",
       "      <td>606.100</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.12632</td>\n",
       "      <td>405</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>-17.341000</td>\n",
       "      <td>-133.788</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.14087</td>\n",
       "      <td>364</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-79.921700</td>\n",
       "      <td>-73.085780</td>\n",
       "      <td>-1325.300</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  SliceNumber  ImageHeight  ImageWidth  \\\n",
       "0  1.2.826.0.1.3680043.25600          155          512         512   \n",
       "1  1.2.826.0.1.3680043.24045          281          512         512   \n",
       "2  1.2.826.0.1.3680043.14348          352          512         512   \n",
       "3  1.2.826.0.1.3680043.12632          405          512         512   \n",
       "4  1.2.826.0.1.3680043.14087          364          512         512   \n",
       "\n",
       "   SliceThickness  ImagePositionPatient_x  ImagePositionPatient_y  \\\n",
       "0           0.625              -71.000000              -38.300000   \n",
       "1           0.500             -115.009300              -52.509310   \n",
       "2           0.600              -46.832031             -255.832031   \n",
       "3           0.625              -64.000000              -17.341000   \n",
       "4           0.500              -79.921700              -73.085780   \n",
       "\n",
       "   ImagePositionPatient_z bboxes  is_positive  split  \n",
       "0                 -74.750     []            0      0  \n",
       "1                1936.500     []            0      0  \n",
       "2                 606.100     []            0      0  \n",
       "3                -133.788     []            0      0  \n",
       "4               -1325.300     []            0      0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Final Subset DataFrame\n",
    "\n",
    "# Separate positives and negatives\n",
    "positive_slices = all_slices_df[all_slices_df['is_positive'] == 1]\n",
    "negative_slices = all_slices_df[all_slices_df['is_positive'] == 0]\n",
    "\n",
    "# Sample negatives\n",
    "negative_subset_list = []\n",
    "for split_id in [0, 1, 2]:\n",
    "    split_negatives = negative_slices[negative_slices['split'] == split_id]\n",
    "    split_positives = positive_slices[positive_slices['split'] == split_id]\n",
    "    \n",
    "    # Use our specified ratio\n",
    "    n_neg = int(len(split_positives) * negative_ratio)\n",
    "    n_neg = min(n_neg, len(split_negatives))\n",
    "    negative_subset_list.append(split_negatives.sample(n=n_neg, random_state=42))\n",
    "\n",
    "negative_subset = pd.concat(negative_subset_list)\n",
    "\n",
    "# Combine everything\n",
    "final_subset_df = pd.concat([positive_slices, negative_subset]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "final_subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:38.330064Z",
     "iopub.status.busy": "2025-11-27T00:12:38.329057Z",
     "iopub.status.idle": "2025-11-27T00:12:38.353059Z",
     "shell.execute_reply": "2025-11-27T00:12:38.351973Z",
     "shell.execute_reply.started": "2025-11-27T00:12:38.330022Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Slices: 20744\n",
      "Val Slices:   4180\n",
      "Test Slices:  3888\n",
      "✅ SUCCESS: No patient leakage detected!\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "print(f\"Train Slices: {len(final_subset_df[final_subset_df['split']==0])}\")\n",
    "print(f\"Val Slices:   {len(final_subset_df[final_subset_df['split']==1])}\")\n",
    "print(f\"Test Slices:  {len(final_subset_df[final_subset_df['split']==2])}\")\n",
    "\n",
    "# Check for leakage\n",
    "train_uids = set(final_subset_df[final_subset_df['split']==0]['StudyInstanceUID'])\n",
    "val_uids   = set(final_subset_df[final_subset_df['split']==1]['StudyInstanceUID'])\n",
    "test_uids  = set(final_subset_df[final_subset_df['split']==2]['StudyInstanceUID'])\n",
    "\n",
    "if len(train_uids.intersection(val_uids)) == 0 and len(train_uids.intersection(test_uids)) == 0:\n",
    "    print('✅ SUCCESS: No patient leakage detected!')\n",
    "else:\n",
    "    print('❌ WARNING: Leakage detected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:42.549384Z",
     "iopub.status.busy": "2025-11-27T00:12:42.548975Z",
     "iopub.status.idle": "2025-11-27T00:12:42.558519Z",
     "shell.execute_reply": "2025-11-27T00:12:42.557578Z",
     "shell.execute_reply.started": "2025-11-27T00:12:42.549354Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                       []\n",
       "1                                                       []\n",
       "2                                                       []\n",
       "3                                                       []\n",
       "4                                                       []\n",
       "                               ...                        \n",
       "28807                                                   []\n",
       "28808                        [[257.0, 160.0, 126.0, 95.0]]\n",
       "28809    [[235.76963, 221.0, 84.23037, 83.94740999999999]]\n",
       "28810                                                   []\n",
       "28811                                                   []\n",
       "Name: bboxes, Length: 28812, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View boxes before box scaling\n",
    "final_subset_df['bboxes'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:51.314565Z",
     "iopub.status.busy": "2025-11-27T00:12:51.314016Z",
     "iopub.status.idle": "2025-11-27T00:12:51.355077Z",
     "shell.execute_reply": "2025-11-27T00:12:51.354211Z",
     "shell.execute_reply.started": "2025-11-27T00:12:51.314533Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding boxes successfully scaled down for 256x256 size.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                       []\n",
       "1                                                       []\n",
       "2                                                       []\n",
       "3                                                       []\n",
       "4                                                       []\n",
       "                               ...                        \n",
       "28807                                                   []\n",
       "28808                          [[128.5, 80.0, 63.0, 47.5]]\n",
       "28809    [[117.884815, 110.5, 42.115185, 41.97370499999...\n",
       "28810                                                   []\n",
       "28811                                                   []\n",
       "Name: bboxes, Length: 28812, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale bounding boxes from original 512x512 to 256x256\n",
    "# We can divide each box coordinate by 2, or multiply by half\n",
    "scale_factor = 0.5\n",
    "\n",
    "def scale_bboxes(bbox_list, scale_factor):\n",
    "    if not bbox_list:  # for negative sample\n",
    "        return []\n",
    "        \n",
    "    scaled_boxes = []\n",
    "    for box in bbox_list:\n",
    "        # Scale each coordinate [x, y, w, h]\n",
    "        scaled_box = [coord * scale_factor for coord in box]\n",
    "        scaled_boxes.append(scaled_box)\n",
    "        \n",
    "    return scaled_boxes\n",
    "\n",
    "# Apply this function to the 'bboxes' column\n",
    "final_subset_df['bboxes'] = final_subset_df['bboxes'].apply(\n",
    "    lambda x: scale_bboxes(x, scale_factor)\n",
    ")\n",
    "\n",
    "print('Bounding boxes successfully scaled down for 256x256 size.')\n",
    "final_subset_df['bboxes'] # after box scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:12:57.264757Z",
     "iopub.status.busy": "2025-11-27T00:12:57.263943Z",
     "iopub.status.idle": "2025-11-27T00:12:57.271139Z",
     "shell.execute_reply": "2025-11-27T00:12:57.270192Z",
     "shell.execute_reply.started": "2025-11-27T00:12:57.264726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Image preprocessing function\n",
    "def load_and_process_dicom(uid, slice_num, target_size):\n",
    "    # Build the local file path\n",
    "    file_path = f'{image_data_path}/{uid}/{slice_num}.dcm'\n",
    "    \n",
    "    ds = pydicom.dcmread(file_path)\n",
    "    \n",
    "    # Get pixel array\n",
    "    img = ds.pixel_array.astype(np.float32)\n",
    "    \n",
    "    # Perform min-max normalization (scales pixel intensity to range [0,1])\n",
    "    img_min = np.min(img)\n",
    "    img_max = np.max(img)\n",
    "    if img_max > img_min:\n",
    "        img = (img - img_min) / (img_max - img_min)\n",
    "    else:\n",
    "        img = np.zeros(img.shape) # Handle black images\n",
    "    \n",
    "    # Resize\n",
    "    img = cv2.resize(img, (target_size, target_size), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:14:01.700733Z",
     "iopub.status.busy": "2025-11-27T00:14:01.699829Z",
     "iopub.status.idle": "2025-11-27T00:24:19.070155Z",
     "shell.execute_reply": "2025-11-27T00:24:19.067952Z",
     "shell.execute_reply.started": "2025-11-27T00:14:01.700694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HDF5 file at /kaggle/working/fracture_dataset_subset.h5 with 28812 total samples...\n",
      "Starting processing loop...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8eaec3472d943989a6ddd94b5472013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing slices:   0%|          | 0/28812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- HDF5 file creation complete! ---\n",
      "File saved to: /kaggle/working/fracture_dataset_subset.h5\n",
      "total 7.1G\n",
      "-rw-r--r-- 1 root root  113 Nov 26 23:23 dataset-metadata.json\n",
      "-rw-r--r-- 1 root root 7.1G Nov 27 00:24 fracture_dataset_subset.h5\n"
     ]
    }
   ],
   "source": [
    "## This cell was made using Google Gemini AI ##\n",
    "\n",
    "num_samples = len(final_subset_df)\n",
    "print(f\"Creating HDF5 file at {hdf5_save_path} with {num_samples} total samples...\")\n",
    "\n",
    "# We'll write in chunks of 32 images at a time\n",
    "image_chunk = (32, image_size, image_size) \n",
    "bbox_chunk = (32, max_boxes, 4)\n",
    "text_chunk = (512,) # A good chunk size for 1D arrays\n",
    "\n",
    "with h5py.File(hdf5_save_path, 'w') as hf:\n",
    "    \n",
    "    # --- Create datasets ---\n",
    "    dset_images = hf.create_dataset('images', shape=(num_samples, image_size, image_size), dtype='f4', chunks=image_chunk)\n",
    "    dset_labels = hf.create_dataset('labels', shape=(num_samples,), dtype='i1', chunks=text_chunk)\n",
    "    dset_bboxes = hf.create_dataset('bboxes', shape=(num_samples, max_boxes, 4), dtype='f4', fillvalue=-1.0, chunks=bbox_chunk)\n",
    "    dt_str = h5py.special_dtype(vlen=str)\n",
    "    dset_uid = hf.create_dataset('StudyInstanceUID', (num_samples,), dtype=dt_str, chunks=text_chunk)\n",
    "    dset_slice = hf.create_dataset('SliceNumber', (num_samples,), dtype=dt_str, chunks=text_chunk)\n",
    "    dset_split = hf.create_dataset('split', shape=(num_samples,), dtype='i1', chunks=text_chunk)\n",
    "\n",
    "    # --- Start the processing loop ---\n",
    "    print(\"Starting processing loop...\")\n",
    "    \n",
    "    for idx, row in tqdm(final_subset_df.iterrows(), total=num_samples, desc=\"Processing slices\"):\n",
    "        try:\n",
    "            # 1. Load and process the image from the local disk\n",
    "            img = load_and_process_dicom(\n",
    "                row['StudyInstanceUID'], \n",
    "                row['SliceNumber'], \n",
    "                image_size\n",
    "            )\n",
    "            \n",
    "            # 2. Save data to HDF5 file\n",
    "            dset_images[idx] = img\n",
    "            dset_labels[idx] = row['is_positive']\n",
    "            dset_uid[idx] = row['StudyInstanceUID']\n",
    "            dset_slice[idx] = str(row['SliceNumber'])\n",
    "            dset_split[idx] = row['split']\n",
    "            \n",
    "            # 3. Process and save bounding boxes\n",
    "            bboxes = row['bboxes']\n",
    "            num_boxes = min(len(bboxes), max_boxes)\n",
    "            \n",
    "            if num_boxes > 0:\n",
    "                dset_bboxes[idx, :num_boxes, :] = np.array(bboxes[:num_boxes])\n",
    "                \n",
    "        except Exception as e:\n",
    "            # This will catch any corrupted files\n",
    "            print(f\"\\n[Warning] Failed to process slice {row['StudyInstanceUID']}/{row['SliceNumber']}: {e}\")\n",
    "\n",
    "print(\"\\n--- HDF5 file creation complete! ---\")\n",
    "print(f\"File saved to: {hdf5_save_path}\")\n",
    "!ls -lh /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:36:29.690365Z",
     "iopub.status.busy": "2025-11-27T00:36:29.689564Z",
     "iopub.status.idle": "2025-11-27T00:36:29.699260Z",
     "shell.execute_reply": "2025-11-27T00:36:29.697998Z",
     "shell.execute_reply.started": "2025-11-27T00:36:29.690291Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Negative Samples: 21609\n",
      "Total Postiive Samples: 7203\n"
     ]
    }
   ],
   "source": [
    "# Count total postive and negative samples\n",
    "with h5py.File(hdf5_save_path, 'r') as f:\n",
    "    labels = f['labels'][:]\n",
    "    total_negative = np.sum(labels == 0)\n",
    "    total_positive = np.sum(labels == 1)\n",
    "\n",
    "print(f'Total Negative Samples: {total_negative}')\n",
    "print(f'Total Postiive Samples: {total_positive}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T23:22:49.836288Z",
     "iopub.status.busy": "2025-11-26T23:22:49.835505Z",
     "iopub.status.idle": "2025-11-26T23:22:50.242679Z",
     "shell.execute_reply": "2025-11-26T23:22:50.241174Z",
     "shell.execute_reply.started": "2025-11-26T23:22:49.836239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API credentials are now in place.\n"
     ]
    }
   ],
   "source": [
    "# Load API credentials from your private api key dataset\n",
    "# If you do not have this private dataset setup, see project README for instructions\n",
    "# Doing this to work around Secret add-ons not working\n",
    "\n",
    "private_secret_dataset_name = 'DATASET_NAME' ### REPLACE WITH YOUR PRIVATE DATASET NAME ###\n",
    "\n",
    "CREDENTIALS_PATH = f'/kaggle/input/{private_secret_dataset_name}/kaggle.json'\n",
    "\n",
    "# Create the hidden .kaggle directory\n",
    "!mkdir -p ~/.kaggle\n",
    "\n",
    "# Copy your key from the private dataset to the correct location\n",
    "!cp '{CREDENTIALS_PATH}' ~/.kaggle/kaggle.json\n",
    "\n",
    "# Set the correct permissions for the file\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print('Kaggle API credentials are now in place.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T00:38:03.984849Z",
     "iopub.status.busy": "2025-11-27T00:38:03.984398Z",
     "iopub.status.idle": "2025-11-27T00:41:00.824188Z",
     "shell.execute_reply": "2025-11-27T00:41:00.822744Z",
     "shell.execute_reply.started": "2025-11-27T00:38:03.984821Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset creation... This will upload 7.05 GB.\n",
      "Starting upload for file fracture_dataset_subset.h5\n",
      "100%|██████████████████████████████████████| 7.05G/7.05G [02:53<00:00, 43.7MB/s]\n",
      "Upload successful: fracture_dataset_subset.h5 (7GB)\n",
      "Starting upload for file .virtual_documents.zip\n",
      "100%|█████████████████████████████████████████| 22.0/22.0 [00:00<00:00, 46.9B/s]\n",
      "Upload successful: .virtual_documents.zip (22B)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/andymalinsky/rsna-2022-hdf5-subset\n"
     ]
    }
   ],
   "source": [
    "# Create the private Kaggle dataset\n",
    "\n",
    "kaggle_username = 'KAGGLE_USERNAME' ### Set KAGGLE_USERNAME ###\n",
    "\n",
    "\n",
    "# Define your dataset metadata\n",
    "dataset_metadata = {\n",
    "  \"title\": \"RSNA 2022 HDF5 Subset\",\n",
    "  \"id\": f\"{kaggle_username}/rsna-2022-hdf5-subset\", \n",
    "  \"licenses\": [\n",
    "    {\n",
    "      \"name\": \"CC0-1.0\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Write the metadata file\n",
    "with open('/kaggle/working/dataset-metadata.json', 'w') as f:\n",
    "    json.dump(dataset_metadata, f)\n",
    "\n",
    "# Run the create command\n",
    "# You may have to wait a few minutes for the dataset to fully load to the Kaggle API system\n",
    "print('Starting dataset creation... This will upload 7.05 GB.')\n",
    "!kaggle datasets create -p /kaggle/working/ -r zip"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 4050810,
     "isSourceIdPinned": false,
     "sourceId": 36363,
     "sourceType": "competition"
    },
    {
     "datasetId": 2406209,
     "sourceId": 4264054,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8741187,
     "sourceId": 13738049,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
